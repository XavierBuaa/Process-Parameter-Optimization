{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"data.csv\", header = None)\n",
    "raw_df.rename(columns = {0:'Ae', 1:'Ap', 2:'Rs', 3:'Fz', 4:'label'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_cate(label):\n",
    "    if label >2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['label'] = raw_df.apply(lambda x : re_cate(x.label), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ae</th>\n",
       "      <th>Ap</th>\n",
       "      <th>Rs</th>\n",
       "      <th>Fz</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ae   Ap     Rs    Fz  label\n",
       "0    5.0  2.5   4000  0.05      0\n",
       "1    5.0  2.5   4500  0.05      0\n",
       "2    5.0  2.5   5000  0.05      0\n",
       "3    5.0  2.5   5500  0.05      0\n",
       "4    5.0  2.5   6000  0.05      0\n",
       "5    5.0  2.5   6500  0.05      0\n",
       "6    5.0  2.5   7000  0.05      0\n",
       "7    5.0  2.5   7500  0.05      0\n",
       "8    5.0  2.5   8000  0.05      0\n",
       "9    5.0  2.5   8500  0.05      0\n",
       "10   5.0  2.5   9000  0.05      0\n",
       "11   5.0  2.5   9500  0.05      0\n",
       "12   5.0  2.5  10000  0.05      0\n",
       "13   5.0  2.5  10500  0.05      0\n",
       "14   5.0  2.5  11000  0.05      0\n",
       "15   5.0  2.5  11500  0.05      0\n",
       "16   5.0  2.5  12000  0.05      0\n",
       "17   5.0  2.5  12500  0.05      0\n",
       "18   5.0  2.5  13000  0.05      0\n",
       "19   5.0  2.0   4000  0.05      0\n",
       "20   5.0  2.0   4500  0.05      0\n",
       "21   5.0  2.0   5000  0.05      0\n",
       "22   5.0  2.0   5500  0.05      0\n",
       "23   5.0  2.0   6000  0.05      0\n",
       "24   5.0  2.0   6500  0.05      0\n",
       "25   5.0  2.0   7000  0.05      0\n",
       "26   5.0  2.0   7500  0.05      0\n",
       "27   5.0  2.0   8000  0.05      0\n",
       "28   5.0  2.0   8500  0.05      0\n",
       "29   5.0  2.0   9000  0.05      0\n",
       "..   ...  ...    ...   ...    ...\n",
       "350  0.5  9.0   8000  0.05      1\n",
       "351  0.5  9.0   8500  0.05      0\n",
       "352  0.5  9.0   9000  0.05      1\n",
       "353  0.5  9.0   9500  0.05      1\n",
       "354  0.5  9.0  10000  0.05      1\n",
       "355  0.5  9.0  10500  0.05      0\n",
       "356  0.5  9.0  11000  0.05      0\n",
       "357  0.5  9.0  11500  0.05      1\n",
       "358  0.5  9.0  12000  0.05      1\n",
       "359  0.5  9.0  12500  0.05      1\n",
       "360  0.5  9.0  13000  0.05      1\n",
       "361  0.5  6.0   4000  0.05      1\n",
       "362  0.5  6.0   4500  0.05      1\n",
       "363  0.5  6.0   5000  0.05      1\n",
       "364  0.5  6.0   5500  0.05      1\n",
       "365  0.5  6.0   6000  0.05      1\n",
       "366  0.5  6.0   6500  0.05      1\n",
       "367  0.5  6.0   7000  0.05      1\n",
       "368  0.5  6.0   7500  0.05      1\n",
       "369  0.5  6.0   8000  0.05      1\n",
       "370  0.5  6.0   8500  0.05      1\n",
       "371  0.5  6.0   9000  0.05      1\n",
       "372  0.5  6.0   9500  0.05      1\n",
       "373  0.5  6.0  10000  0.05      1\n",
       "374  0.5  6.0  10500  0.05      1\n",
       "375  0.5  6.0  11000  0.05      1\n",
       "376  0.5  6.0  11500  0.05      1\n",
       "377  0.5  6.0  12000  0.05      1\n",
       "378  0.5  6.0  12500  0.05      1\n",
       "379  0.5  6.0  13000  0.05      1\n",
       "\n",
       "[380 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "raw_matrix = raw_df.as_matrix()\n",
    "raw_feature = raw_matrix[:, 0:-2]\n",
    "raw_label = raw_matrix[:, -1]\n",
    "raw_feature_mean = raw_feature.mean(axis = 0)\n",
    "raw_feature_std = raw_feature.std(axis = 0)\n",
    "raw_feature_normalized = (raw_feature - raw_feature_mean)/raw_feature_std\n",
    "#np.random.shuffle(raw_feature_normalized)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=4, tol=1e-6, max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  39 \t Pre_Accuracy :  0.6923076923076923 \t\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  24 \t NumofIns :  39 \t Pre_Accuracy :  0.6153846153846154 \t\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  38 \t Pre_Accuracy :  0.6842105263157895 \t\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  38 \t Pre_Accuracy :  0.6842105263157895 \t\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  21 \t NumofIns :  38 \t Pre_Accuracy :  0.5526315789473685 \t\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  22 \t NumofIns :  38 \t Pre_Accuracy :  0.5789473684210527 \t\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  24 \t NumofIns :  37 \t Pre_Accuracy :  0.6486486486486487 \t\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  37 \t Pre_Accuracy :  0.7027027027027027 \t\n",
      "mean of NumofIns precisely classified 0.6580096290622607\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    lr.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = lr.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            pre_label_num += 1\n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "\n",
    "print('mean of NumofIns precisely classified',numpy.mean(test_pre_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf',decision_function_shape='ovo',C=20,shrinking =False,tol =1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  35 \t NumofIns :  38 \t Pre_Accuracy :  0.9210526315789473 \t\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  34 \t NumofIns :  38 \t Pre_Accuracy :  0.8947368421052632 \t\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  28 \t NumofIns :  38 \t Pre_Accuracy :  0.7368421052631579 \t\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  32 \t NumofIns :  38 \t Pre_Accuracy :  0.8421052631578947 \t\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  28 \t NumofIns :  37 \t Pre_Accuracy :  0.7567567567567568 \t\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  32 \t NumofIns :  37 \t Pre_Accuracy :  0.8648648648648649 \t\n",
      "mean of NumofIns precisely classified 0.813241784294416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "F:\\Anaconda\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    SVM.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = SVM.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            pre_label_num += 1\n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "\n",
    "print('mean of NumofIns precisely classified',numpy.mean(test_pre_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_C = XGBClassifier(\n",
    "    #booster = 'gblinear',\n",
    "    #objective='multi:softmax',\n",
    "    #num_class=7,#必须要考虑到0的情况。这个数据集里面没有零\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    min_child_weight = 5,\n",
    "    scale_pos_weight = 5,\n",
    "    num_boost_round =5,\n",
    "    max_delta_step=1000,\n",
    "    alpha =2,\n",
    "    eta=1\n",
    "    #colsample_bytree=0.9\n",
    "    #gamma=5,\n",
    "    #process_type='update'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  35 \t NumofIns :  39 \t Pre_Accuracy :  0.8974358974358975 \t\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  30 \t NumofIns :  38 \t Pre_Accuracy :  0.7894736842105263 \t\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  34 \t NumofIns :  38 \t Pre_Accuracy :  0.8947368421052632 \t\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  37 \t Pre_Accuracy :  0.8378378378378378 \t\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  30 \t NumofIns :  37 \t Pre_Accuracy :  0.8108108108108109 \t\n",
      "mean of NumofIns precisely classified 0.8288324762008973\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    XGB_C.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = XGB_C.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            pre_label_num += 1\n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "\n",
    "print('mean of NumofIns precisely classified',numpy.mean(test_pre_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
