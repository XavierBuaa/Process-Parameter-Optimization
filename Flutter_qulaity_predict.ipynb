{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.externals import joblib\n",
    "import numpy\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"./dataset/data.csv\", header = None)\n",
    "raw_df.rename(columns = {0:'Ae', 1:'Ap', 2:'Rs', 3:'Fz', 4:'label'}, inplace = True)\n",
    "pred_df1 = raw_df[0:19]\n",
    "pred_df2 = raw_df[38:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ae</th>\n",
       "      <th>Ap</th>\n",
       "      <th>Rs</th>\n",
       "      <th>Fz</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ae   Ap     Rs    Fz  label\n",
       "0   5.0  2.5   4000  0.05      1\n",
       "1   5.0  2.5   4500  0.05      0\n",
       "2   5.0  2.5   5000  0.05      0\n",
       "3   5.0  2.5   5500  0.05      1\n",
       "4   5.0  2.5   6000  0.05      0\n",
       "5   5.0  2.5   6500  0.05      1\n",
       "6   5.0  2.5   7000  0.05      0\n",
       "7   5.0  2.5   7500  0.05      1\n",
       "8   5.0  2.5   8000  0.05      0\n",
       "9   5.0  2.5   8500  0.05      0\n",
       "10  5.0  2.5   9000  0.05      0\n",
       "11  5.0  2.5   9500  0.05      2\n",
       "12  5.0  2.5  10000  0.05      0\n",
       "13  5.0  2.5  10500  0.05      0\n",
       "14  5.0  2.5  11000  0.05      1\n",
       "15  5.0  2.5  11500  0.05      1\n",
       "16  5.0  2.5  12000  0.05      2\n",
       "17  5.0  2.5  12500  0.05      2\n",
       "18  5.0  2.5  13000  0.05      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ae</th>\n",
       "      <th>Ap</th>\n",
       "      <th>Rs</th>\n",
       "      <th>Fz</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>9500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>11500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ae   Ap     Rs    Fz  label\n",
       "38  5.0  1.5   4000  0.05      4\n",
       "39  5.0  1.5   4500  0.05      1\n",
       "40  5.0  1.5   5000  0.05      1\n",
       "41  5.0  1.5   5500  0.05      3\n",
       "42  5.0  1.5   6000  0.05      1\n",
       "43  5.0  1.5   6500  0.05      4\n",
       "44  5.0  1.5   7000  0.05      1\n",
       "45  5.0  1.5   7500  0.05      4\n",
       "46  5.0  1.5   8000  0.05      1\n",
       "47  5.0  1.5   8500  0.05      1\n",
       "48  5.0  1.5   9000  0.05      1\n",
       "49  5.0  1.5   9500  0.05      4\n",
       "50  5.0  1.5  10000  0.05      0\n",
       "51  5.0  1.5  10500  0.05      0\n",
       "52  5.0  1.5  11000  0.05      1\n",
       "53  5.0  1.5  11500  0.05      4\n",
       "54  5.0  1.5  12000  0.05      4\n",
       "55  5.0  1.5  12500  0.05      4\n",
       "56  5.0  1.5  13000  0.05      4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_cate(label):\n",
    "    if label >2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['label'] = raw_df.apply(lambda x : re_cate(x.label), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "raw_matrix = raw_df.as_matrix()\n",
    "raw_feature = raw_matrix[:, 0:-2]\n",
    "raw_label = raw_matrix[:, -1]\n",
    "raw_feature_mean = raw_feature.mean(axis = 0)\n",
    "raw_feature_std = raw_feature.std(axis = 0)\n",
    "raw_feature_normalized = (raw_feature - raw_feature_mean)/raw_feature_std\n",
    "#np.random.shuffle(raw_feature_normalized)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred_matrix1 = pred_df1.as_matrix()\n",
    "pred_feature1 = pred_matrix1[:, 0:-2]\n",
    "pred_feature_normalized1 = (pred_feature1 - raw_feature_mean)/raw_feature_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pred_matrix2 = pred_df2.as_matrix()\n",
    "pred_feature2 = pred_matrix2[:, 0:-2]\n",
    "pred_feature_normalized2 = (pred_feature2 - raw_feature_mean)/raw_feature_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=4, tol=1e-6, max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  39 \t Pre_Accuracy :  0.6923076923076923 \t\n",
      "TP: 20\n",
      "FP: 10\n",
      "FN: 2\n",
      "TN: 7\n",
      "0.6923076923076923\n",
      "0.6666666666666666\n",
      "0.9090909090909091\n",
      "0.7692307692307692\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  24 \t NumofIns :  39 \t Pre_Accuracy :  0.6153846153846154 \t\n",
      "TP: 19\n",
      "FP: 12\n",
      "FN: 3\n",
      "TN: 5\n",
      "0.6153846153846154\n",
      "0.6129032258064516\n",
      "0.8636363636363636\n",
      "0.7169811320754716\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "TP: 14\n",
      "FP: 3\n",
      "FN: 8\n",
      "TN: 13\n",
      "0.7105263157894737\n",
      "0.8235294117647058\n",
      "0.6363636363636364\n",
      "0.717948717948718\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  38 \t Pre_Accuracy :  0.6842105263157895 \t\n",
      "TP: 16\n",
      "FP: 6\n",
      "FN: 6\n",
      "TN: 10\n",
      "0.6842105263157895\n",
      "0.7272727272727273\n",
      "0.7272727272727273\n",
      "0.7272727272727273\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  38 \t Pre_Accuracy :  0.6842105263157895 \t\n",
      "TP: 15\n",
      "FP: 5\n",
      "FN: 7\n",
      "TN: 11\n",
      "0.6842105263157895\n",
      "0.75\n",
      "0.6818181818181818\n",
      "0.7142857142857143\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "TP: 18\n",
      "FP: 7\n",
      "FN: 4\n",
      "TN: 9\n",
      "0.7105263157894737\n",
      "0.72\n",
      "0.8181818181818182\n",
      "0.7659574468085107\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  21 \t NumofIns :  38 \t Pre_Accuracy :  0.5526315789473685 \t\n",
      "TP: 15\n",
      "FP: 10\n",
      "FN: 7\n",
      "TN: 6\n",
      "0.5526315789473685\n",
      "0.6\n",
      "0.6818181818181818\n",
      "0.6382978723404256\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  22 \t NumofIns :  38 \t Pre_Accuracy :  0.5789473684210527 \t\n",
      "TP: 18\n",
      "FP: 12\n",
      "FN: 4\n",
      "TN: 4\n",
      "0.5789473684210527\n",
      "0.6\n",
      "0.8181818181818182\n",
      "0.6923076923076923\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  24 \t NumofIns :  37 \t Pre_Accuracy :  0.6486486486486487 \t\n",
      "TP: 13\n",
      "FP: 5\n",
      "FN: 8\n",
      "TN: 11\n",
      "0.6486486486486487\n",
      "0.7222222222222222\n",
      "0.6190476190476191\n",
      "0.6666666666666666\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  26 \t NumofIns :  37 \t Pre_Accuracy :  0.7027027027027027 \t\n",
      "TP: 17\n",
      "FP: 7\n",
      "FN: 4\n",
      "TN: 9\n",
      "0.7027027027027027\n",
      "0.7083333333333334\n",
      "0.8095238095238095\n",
      "0.7555555555555556\n",
      "mean of NumofIns precisely classified 0.6580096290622607\n",
      "mean of accuracy 0.6580096290622607\n",
      "mean of precision 0.6930927587066107\n",
      "mean of recall 0.7564935064935064\n",
      "mean of f1 0.7164504294492251\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "lr_output_dir = './model_accuracy_jupyter/LR/'\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    lr.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = lr.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "  \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "                \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    model_output_name = lr_output_dir + \"model_%d\"%(count_CV)\n",
    "    joblib.dump(lr, model_output_name)\n",
    "\n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_lr_name = './model_accuracy_jupyter/LR/model_1'\n",
    "trained_lr = joblib.load(train_lr_name)\n",
    "lr_pred_result1 = trained_lr.predict(pred_feature_normalized1)\n",
    "print(lr_pred_result1)\n",
    "lr_pred_result2 = trained_lr.predict(pred_feature_normalized2)\n",
    "print(lr_pred_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf',decision_function_shape='ovo',C=20,shrinking =False,tol =1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "TP: 20\n",
      "FP: 6\n",
      "FN: 2\n",
      "TN: 11\n",
      "0.7948717948717948\n",
      "0.7692307692307693\n",
      "0.9090909090909091\n",
      "0.8333333333333333\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "TP: 18\n",
      "FP: 4\n",
      "FN: 4\n",
      "TN: 13\n",
      "0.7948717948717948\n",
      "0.8181818181818182\n",
      "0.8181818181818182\n",
      "0.8181818181818182\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  35 \t NumofIns :  38 \t Pre_Accuracy :  0.9210526315789473 \t\n",
      "TP: 22\n",
      "FP: 3\n",
      "FN: 0\n",
      "TN: 13\n",
      "0.9210526315789473\n",
      "0.88\n",
      "1.0\n",
      "0.9361702127659575\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  27 \t NumofIns :  38 \t Pre_Accuracy :  0.7105263157894737 \t\n",
      "TP: 18\n",
      "FP: 7\n",
      "FN: 4\n",
      "TN: 9\n",
      "0.7105263157894737\n",
      "0.72\n",
      "0.8181818181818182\n",
      "0.7659574468085107\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  34 \t NumofIns :  38 \t Pre_Accuracy :  0.8947368421052632 \t\n",
      "TP: 19\n",
      "FP: 1\n",
      "FN: 3\n",
      "TN: 15\n",
      "0.8947368421052632\n",
      "0.95\n",
      "0.8636363636363636\n",
      "0.9047619047619048\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  28 \t NumofIns :  38 \t Pre_Accuracy :  0.7368421052631579 \t\n",
      "TP: 17\n",
      "FP: 5\n",
      "FN: 5\n",
      "TN: 11\n",
      "0.7368421052631579\n",
      "0.7727272727272727\n",
      "0.7727272727272727\n",
      "0.7727272727272727\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  32 \t NumofIns :  38 \t Pre_Accuracy :  0.8421052631578947 \t\n",
      "TP: 21\n",
      "FP: 5\n",
      "FN: 1\n",
      "TN: 11\n",
      "0.8421052631578947\n",
      "0.8076923076923077\n",
      "0.9545454545454546\n",
      "0.875\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "TP: 18\n",
      "FP: 3\n",
      "FN: 4\n",
      "TN: 13\n",
      "0.8157894736842105\n",
      "0.8571428571428571\n",
      "0.8181818181818182\n",
      "0.8372093023255814\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  28 \t NumofIns :  37 \t Pre_Accuracy :  0.7567567567567568 \t\n",
      "TP: 16\n",
      "FP: 4\n",
      "FN: 5\n",
      "TN: 12\n",
      "0.7567567567567568\n",
      "0.8\n",
      "0.7619047619047619\n",
      "0.7804878048780488\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  32 \t NumofIns :  37 \t Pre_Accuracy :  0.8648648648648649 \t\n",
      "TP: 20\n",
      "FP: 4\n",
      "FN: 1\n",
      "TN: 12\n",
      "0.8648648648648649\n",
      "0.8333333333333334\n",
      "0.9523809523809523\n",
      "0.888888888888889\n",
      "mean of NumofIns precisely classified 0.813241784294416\n",
      "mean of accuracy 0.813241784294416\n",
      "mean of precision 0.8208308358308358\n",
      "mean of recall 0.8668831168831168\n",
      "mean of f1 0.8412717984671316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "svm_output_dir = './model_accuracy_jupyter/SVM/'\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    SVM.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = SVM.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "  \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "                \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    model_output_name = svm_output_dir + \"model_%d\"%(count_CV)\n",
    "    joblib.dump(lr, model_output_name)\n",
    "\n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_svm_name = './model_accuracy_jupyter/SVM/model_1'\n",
    "trained_svm = joblib.load(train_svm_name)\n",
    "svm_pred_result1 = trained_svm.predict(pred_feature_normalized1)\n",
    "print(svm_pred_result1)\n",
    "svm_pred_result2 = trained_svm.predict(pred_feature_normalized2)\n",
    "print(svm_pred_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_C = XGBClassifier(\n",
    "    #booster = 'gblinear',\n",
    "    #objective='multi:softmax',\n",
    "    #num_class=7,#必须要考虑到0的情况。这个数据集里面没有零\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    min_child_weight = 5,\n",
    "    scale_pos_weight = 5,\n",
    "    num_boost_round =5,\n",
    "    max_delta_step=1000,\n",
    "    alpha =2,\n",
    "    eta=1\n",
    "    #colsample_bytree=0.9\n",
    "    #gamma=5,\n",
    "    #process_type='update'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  39 \t Pre_Accuracy :  0.7948717948717948 \t\n",
      "TP: 22\n",
      "FP: 8\n",
      "FN: 0\n",
      "TN: 9\n",
      "0.7948717948717948\n",
      "0.7333333333333333\n",
      "1.0\n",
      "0.846153846153846\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  35 \t NumofIns :  39 \t Pre_Accuracy :  0.8974358974358975 \t\n",
      "TP: 22\n",
      "FP: 4\n",
      "FN: 0\n",
      "TN: 13\n",
      "0.8974358974358975\n",
      "0.8461538461538461\n",
      "1.0\n",
      "0.9166666666666666\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "TP: 22\n",
      "FP: 7\n",
      "FN: 0\n",
      "TN: 9\n",
      "0.8157894736842105\n",
      "0.7586206896551724\n",
      "1.0\n",
      "0.8627450980392156\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  30 \t NumofIns :  38 \t Pre_Accuracy :  0.7894736842105263 \t\n",
      "TP: 22\n",
      "FP: 8\n",
      "FN: 0\n",
      "TN: 8\n",
      "0.7894736842105263\n",
      "0.7333333333333333\n",
      "1.0\n",
      "0.846153846153846\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  34 \t NumofIns :  38 \t Pre_Accuracy :  0.8947368421052632 \t\n",
      "TP: 21\n",
      "FP: 3\n",
      "FN: 1\n",
      "TN: 13\n",
      "0.8947368421052632\n",
      "0.875\n",
      "0.9545454545454546\n",
      "0.9130434782608695\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "TP: 20\n",
      "FP: 5\n",
      "FN: 2\n",
      "TN: 11\n",
      "0.8157894736842105\n",
      "0.8\n",
      "0.9090909090909091\n",
      "0.8510638297872342\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "TP: 22\n",
      "FP: 7\n",
      "FN: 0\n",
      "TN: 9\n",
      "0.8157894736842105\n",
      "0.7586206896551724\n",
      "1.0\n",
      "0.8627450980392156\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  38 \t Pre_Accuracy :  0.8157894736842105 \t\n",
      "TP: 21\n",
      "FP: 6\n",
      "FN: 1\n",
      "TN: 10\n",
      "0.8157894736842105\n",
      "0.7777777777777778\n",
      "0.9545454545454546\n",
      "0.8571428571428572\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  31 \t NumofIns :  37 \t Pre_Accuracy :  0.8378378378378378 \t\n",
      "TP: 19\n",
      "FP: 4\n",
      "FN: 2\n",
      "TN: 12\n",
      "0.8378378378378378\n",
      "0.8260869565217391\n",
      "0.9047619047619048\n",
      "0.8636363636363636\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  30 \t NumofIns :  37 \t Pre_Accuracy :  0.8108108108108109 \t\n",
      "TP: 20\n",
      "FP: 6\n",
      "FN: 1\n",
      "TN: 10\n",
      "0.8108108108108109\n",
      "0.7692307692307693\n",
      "0.9523809523809523\n",
      "0.8510638297872339\n",
      "mean of NumofIns precisely classified 0.8288324762008973\n",
      "mean of accuracy 0.8288324762008973\n",
      "mean of precision 0.7878157395661144\n",
      "mean of recall 0.9675324675324676\n",
      "mean of f1 0.8670414913667349\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "xgboost_output_dir = './model_accuracy_jupyter/XGBoost/'\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    XGB_C.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = XGB_C.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "  \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "                \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    model_output_name = xgboost_output_dir + \"model_%d\"%(count_CV)\n",
    "    joblib.dump(lr, model_output_name)\n",
    "    \n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost_name = './model_accuracy_jupyter/XGBoost/model_1'\n",
    "trained_xgboost = joblib.load(train_xgboost_name)\n",
    "xgboost_pred_result1 = trained_xgboost.predict(pred_feature_normalized1)\n",
    "print(xgboost_pred_result1)\n",
    "xgboost_pred_result2 = trained_xgboost.predict(pred_feature_normalized2)\n",
    "print(xgboost_pred_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
