{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_cate(label):\n",
    "    if label >37.2 and label < 37.6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"./dataset/moment_table.csv\", header = None)\n",
    "raw_df.rename(columns = {0:'moment', 1:'flatness', 2:'distance'}, inplace = True)\n",
    "raw_df['distance'] = raw_df.apply(lambda x : re_cate(x.distance), axis = 1)\n",
    "raw_label = raw_df['distance'].as_matrix()\n",
    "raw_df.drop(columns = ['distance'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>moment</th>\n",
       "      <th>flatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.5</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57.5</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>62.5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67.5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72.5</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77.5</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.5</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>87.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>92.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>97.5</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>102.5</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>107.5</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>112.5</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>117.5</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>52.5</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>57.5</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>62.5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>67.5</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>72.5</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>77.5</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>82.5</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>87.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>92.5</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>97.5</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>102.5</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>107.5</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>110.0</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>112.5</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>115.0</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>117.5</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    moment  flatness\n",
       "0     50.0      0.01\n",
       "1     52.5      0.01\n",
       "2     55.0      0.01\n",
       "3     57.5      0.01\n",
       "4     60.0      0.02\n",
       "5     62.5      0.02\n",
       "6     65.0      0.02\n",
       "7     67.5      0.02\n",
       "8     70.0      0.02\n",
       "9     72.5      0.03\n",
       "10    75.0      0.03\n",
       "11    77.5      0.03\n",
       "12    80.0      0.04\n",
       "13    82.5      0.04\n",
       "14    85.0      0.05\n",
       "15    87.5      0.05\n",
       "16    90.0      0.05\n",
       "17    92.5      0.05\n",
       "18    95.0      0.06\n",
       "19    97.5      0.06\n",
       "20   100.0      0.06\n",
       "21   102.5      0.06\n",
       "22   105.0      0.07\n",
       "23   107.5      0.07\n",
       "24   110.0      0.07\n",
       "25   112.5      0.08\n",
       "26   115.0      0.08\n",
       "27   117.5      0.09\n",
       "28   120.0      0.10\n",
       "29    50.0      0.01\n",
       "..     ...       ...\n",
       "57   120.0      0.10\n",
       "58    50.0      0.01\n",
       "59    52.5      0.01\n",
       "60    55.0      0.01\n",
       "61    57.5      0.01\n",
       "62    60.0      0.02\n",
       "63    62.5      0.02\n",
       "64    65.0      0.02\n",
       "65    67.5      0.02\n",
       "66    70.0      0.02\n",
       "67    72.5      0.03\n",
       "68    75.0      0.03\n",
       "69    77.5      0.03\n",
       "70    80.0      0.04\n",
       "71    82.5      0.04\n",
       "72    85.0      0.05\n",
       "73    87.5      0.05\n",
       "74    90.0      0.05\n",
       "75    92.5      0.05\n",
       "76    95.0      0.06\n",
       "77    97.5      0.06\n",
       "78   100.0      0.06\n",
       "79   102.5      0.06\n",
       "80   105.0      0.07\n",
       "81   107.5      0.07\n",
       "82   110.0      0.07\n",
       "83   112.5      0.08\n",
       "84   115.0      0.08\n",
       "85   117.5      0.09\n",
       "86   120.0      0.10\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "raw_feature = raw_df.as_matrix()\n",
    "raw_feature_mean = raw_feature.mean(axis = 0)\n",
    "raw_feature_std = raw_feature.std(axis = 0)\n",
    "raw_feature_normalized = (raw_feature - raw_feature_mean)/raw_feature_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.67332005, -1.36965201],\n",
       "       [-1.55379719, -1.36965201],\n",
       "       [-1.43427433, -1.36965201],\n",
       "       [-1.31475147, -1.36965201],\n",
       "       [-1.19522861, -0.98024114],\n",
       "       [-1.07570575, -0.98024114],\n",
       "       [-0.95618289, -0.98024114],\n",
       "       [-0.83666003, -0.98024114],\n",
       "       [-0.71713717, -0.98024114],\n",
       "       [-0.5976143 , -0.59083028],\n",
       "       [-0.47809144, -0.59083028],\n",
       "       [-0.35856858, -0.59083028],\n",
       "       [-0.23904572, -0.20141941],\n",
       "       [-0.11952286, -0.20141941],\n",
       "       [ 0.        ,  0.18799145],\n",
       "       [ 0.11952286,  0.18799145],\n",
       "       [ 0.23904572,  0.18799145],\n",
       "       [ 0.35856858,  0.18799145],\n",
       "       [ 0.47809144,  0.57740232],\n",
       "       [ 0.5976143 ,  0.57740232],\n",
       "       [ 0.71713717,  0.57740232],\n",
       "       [ 0.83666003,  0.57740232],\n",
       "       [ 0.95618289,  0.96681318],\n",
       "       [ 1.07570575,  0.96681318],\n",
       "       [ 1.19522861,  0.96681318],\n",
       "       [ 1.31475147,  1.35622405],\n",
       "       [ 1.43427433,  1.35622405],\n",
       "       [ 1.55379719,  1.74563491],\n",
       "       [ 1.67332005,  2.13504578],\n",
       "       [-1.67332005, -1.36965201],\n",
       "       [-1.55379719, -1.36965201],\n",
       "       [-1.43427433, -1.36965201],\n",
       "       [-1.31475147, -1.36965201],\n",
       "       [-1.19522861, -0.98024114],\n",
       "       [-1.07570575, -0.98024114],\n",
       "       [-0.95618289, -0.98024114],\n",
       "       [-0.83666003, -0.98024114],\n",
       "       [-0.71713717, -0.98024114],\n",
       "       [-0.5976143 , -0.59083028],\n",
       "       [-0.47809144, -0.59083028],\n",
       "       [-0.35856858, -0.59083028],\n",
       "       [-0.23904572, -0.20141941],\n",
       "       [-0.11952286, -0.20141941],\n",
       "       [ 0.        ,  0.18799145],\n",
       "       [ 0.11952286,  0.18799145],\n",
       "       [ 0.23904572,  0.18799145],\n",
       "       [ 0.35856858,  0.18799145],\n",
       "       [ 0.47809144,  0.57740232],\n",
       "       [ 0.5976143 ,  0.57740232],\n",
       "       [ 0.71713717,  0.57740232],\n",
       "       [ 0.83666003,  0.57740232],\n",
       "       [ 0.95618289,  0.96681318],\n",
       "       [ 1.07570575,  0.96681318],\n",
       "       [ 1.19522861,  0.96681318],\n",
       "       [ 1.31475147,  1.35622405],\n",
       "       [ 1.43427433,  1.35622405],\n",
       "       [ 1.55379719,  1.74563491],\n",
       "       [ 1.67332005,  2.13504578],\n",
       "       [-1.67332005, -1.36965201],\n",
       "       [-1.55379719, -1.36965201],\n",
       "       [-1.43427433, -1.36965201],\n",
       "       [-1.31475147, -1.36965201],\n",
       "       [-1.19522861, -0.98024114],\n",
       "       [-1.07570575, -0.98024114],\n",
       "       [-0.95618289, -0.98024114],\n",
       "       [-0.83666003, -0.98024114],\n",
       "       [-0.71713717, -0.98024114],\n",
       "       [-0.5976143 , -0.59083028],\n",
       "       [-0.47809144, -0.59083028],\n",
       "       [-0.35856858, -0.59083028],\n",
       "       [-0.23904572, -0.20141941],\n",
       "       [-0.11952286, -0.20141941],\n",
       "       [ 0.        ,  0.18799145],\n",
       "       [ 0.11952286,  0.18799145],\n",
       "       [ 0.23904572,  0.18799145],\n",
       "       [ 0.35856858,  0.18799145],\n",
       "       [ 0.47809144,  0.57740232],\n",
       "       [ 0.5976143 ,  0.57740232],\n",
       "       [ 0.71713717,  0.57740232],\n",
       "       [ 0.83666003,  0.57740232],\n",
       "       [ 0.95618289,  0.96681318],\n",
       "       [ 1.07570575,  0.96681318],\n",
       "       [ 1.19522861,  0.96681318],\n",
       "       [ 1.31475147,  1.35622405],\n",
       "       [ 1.43427433,  1.35622405],\n",
       "       [ 1.55379719,  1.74563491],\n",
       "       [ 1.67332005,  2.13504578]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_feature_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg', multi_class='multinomial', C=4, tol=1e-6, max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 6\n",
      "FP: 2\n",
      "FN: 0\n",
      "TN: 1\n",
      "0.7777777777777778\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 1\n",
      "TN: 2\n",
      "0.7777777777777778\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 6\n",
      "FP: 2\n",
      "FN: 0\n",
      "TN: 1\n",
      "0.7777777777777778\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 6\n",
      "FP: 2\n",
      "FN: 0\n",
      "TN: 1\n",
      "0.7777777777777778\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 1\n",
      "TN: 2\n",
      "0.7777777777777778\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  5 \t NumofIns :  8 \t Pre_Accuracy :  0.625 \t\n",
      "TP: 4\n",
      "FP: 2\n",
      "FN: 1\n",
      "TN: 1\n",
      "0.625\n",
      "0.6666666666666666\n",
      "0.8\n",
      "0.7272727272727272\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  8 \t Pre_Accuracy :  0.875 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.875\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  8 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "mean of NumofIns precisely classified 0.8277777777777778\n",
      "mean of accuracy 0.8277777777777778\n",
      "mean of precision 0.8273809523809523\n",
      "mean of recall 0.9466666666666667\n",
      "mean of f1 0.8797535797535797\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    lr.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = lr.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "            \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel='rbf',decision_function_shape='ovo',C=20,shrinking =False,tol =1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 1\n",
      "TN: 3\n",
      "0.8888888888888888\n",
      "1.0\n",
      "0.8333333333333334\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 1\n",
      "TN: 3\n",
      "0.8888888888888888\n",
      "1.0\n",
      "0.8333333333333334\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  8 \t Pre_Accuracy :  0.875 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.875\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  8 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  8 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 5\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "mean of NumofIns precisely classified 0.9541666666666666\n",
      "mean of accuracy 0.9541666666666666\n",
      "mean of precision 0.9690476190476189\n",
      "mean of recall 0.9666666666666668\n",
      "mean of f1 0.965034965034965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    SVM.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = SVM.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "            \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_C = XGBClassifier(\n",
    "    #booster = 'gblinear',\n",
    "    #objective='multi:softmax',\n",
    "    #num_class=7,#必须要考虑到0的情况。这个数据集里面没有零\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    min_child_weight = 5,\n",
    "    scale_pos_weight = 5,\n",
    "    num_boost_round =5,\n",
    "    max_delta_step=1000,\n",
    "    alpha =2,\n",
    "    eta=1\n",
    "    #colsample_bytree=0.9\n",
    "    #gamma=5,\n",
    "    #process_type='update'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### In Cross Validation 0: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 1: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 2: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  9 \t Pre_Accuracy :  0.7777777777777778 \t\n",
      "TP: 6\n",
      "FP: 2\n",
      "FN: 0\n",
      "TN: 1\n",
      "0.7777777777777778\n",
      "0.75\n",
      "1.0\n",
      "0.8571428571428571\n",
      "#### In Cross Validation 3: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 4: ####\n",
      "NumofIns Precisely Classified :  8 \t NumofIns :  9 \t Pre_Accuracy :  0.8888888888888888 \t\n",
      "TP: 6\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.8888888888888888\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.923076923076923\n",
      "#### In Cross Validation 5: ####\n",
      "NumofIns Precisely Classified :  9 \t NumofIns :  9 \t Pre_Accuracy :  1.0 \t\n",
      "TP: 6\n",
      "FP: 0\n",
      "FN: 0\n",
      "TN: 3\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "#### In Cross Validation 6: ####\n",
      "NumofIns Precisely Classified :  6 \t NumofIns :  9 \t Pre_Accuracy :  0.6666666666666666 \t\n",
      "TP: 4\n",
      "FP: 1\n",
      "FN: 2\n",
      "TN: 2\n",
      "0.6666666666666666\n",
      "0.8\n",
      "0.6666666666666666\n",
      "0.7272727272727272\n",
      "#### In Cross Validation 7: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  8 \t Pre_Accuracy :  0.875 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.875\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 8: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  8 \t Pre_Accuracy :  0.875 \t\n",
      "TP: 5\n",
      "FP: 1\n",
      "FN: 0\n",
      "TN: 2\n",
      "0.875\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "#### In Cross Validation 9: ####\n",
      "NumofIns Precisely Classified :  7 \t NumofIns :  8 \t Pre_Accuracy :  0.875 \t\n",
      "TP: 4\n",
      "FP: 0\n",
      "FN: 1\n",
      "TN: 3\n",
      "0.875\n",
      "1.0\n",
      "0.8\n",
      "0.888888888888889\n",
      "mean of NumofIns precisely classified 0.8625\n",
      "mean of accuracy 0.8625\n",
      "mean of precision 0.8645238095238096\n",
      "mean of recall 0.9466666666666667\n",
      "mean of f1 0.8983793983793984\n"
     ]
    }
   ],
   "source": [
    "count_CV = 0\n",
    "test_acc_record = []\n",
    "test_pre_record = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for train_index,test_index in kfold.split(raw_feature_normalized, raw_label):\n",
    "    XGB_C.fit(raw_feature_normalized[train_index], raw_label[train_index])\n",
    "    pred_smile_label = XGB_C.predict(raw_feature_normalized[test_index])\n",
    "    real_label = raw_label[test_index]\n",
    "    \n",
    "    TP_num = 0\n",
    "    FP_num = 0\n",
    "    FN_num = 0\n",
    "    TN_num = 0\n",
    "\n",
    "    \n",
    "    test_count_num = 0\n",
    "    real_label_index = 0\n",
    "    pre_label_num = 0\n",
    "    \n",
    "    for label in pred_smile_label:\n",
    "        if label == real_label[real_label_index]:\n",
    "            if label == 0:\n",
    "                TN_num += 1\n",
    "            if label == 1:\n",
    "                TP_num += 1\n",
    "            pre_label_num += 1\n",
    "        else:\n",
    "            if label == 0:\n",
    "                FN_num += 1\n",
    "            if label == 1:\n",
    "                FP_num += 1\n",
    "            \n",
    "        real_label_index += 1\n",
    "        test_count_num += 1\n",
    "    \n",
    "    print('#### In Cross Validation %d: ####'% count_CV)\n",
    "    count_CV += 1\n",
    "    print('NumofIns Precisely Classified : ',pre_label_num,'\\t',\n",
    "          'NumofIns : ',test_count_num,'\\t',\n",
    "          'Pre_Accuracy : ',pre_label_num/test_count_num,'\\t',)\n",
    "    \n",
    "    test_pre_record.append(pre_label_num/test_count_num)\n",
    "    print(\"TP:\", TP_num)\n",
    "    print(\"FP:\", FP_num)\n",
    "    print(\"FN:\", FN_num)\n",
    "    print(\"TN:\", TN_num)\n",
    "    accuracy = (TP_num + TN_num)/(TP_num + FP_num + FN_num + TN_num)\n",
    "    precision = TP_num/(TP_num + FP_num)\n",
    "    recall = TP_num/(TP_num + FN_num)\n",
    "    f1 = (2 * precision * recall)/(precision + recall)\n",
    "    print(accuracy)\n",
    "    print(precision)\n",
    "    print(recall)\n",
    "    print(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "print('mean of NumofIns precisely classified',np.mean(test_pre_record))\n",
    "print('mean of accuracy',np.mean(accuracy_list))\n",
    "print('mean of precision',np.mean(precision_list))\n",
    "print('mean of recall',np.mean(recall_list))\n",
    "print('mean of f1',np.mean(f1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
